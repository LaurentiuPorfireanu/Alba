"""
Test script pentru preprocessing pipeline
"""

import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'detector'))

from src.services.data_processor import DataProcessor
from src.services.feature_extractor import NetworkFeatureExtractor
from loguru import logger
import pandas as pd
import numpy as np

def test_data_preprocessing():
    """Test complete preprocessing pipeline"""
    logger.info("=== Testing Data Preprocessing Pipeline ===")
    
    # Initialize processor
    processor = DataProcessor()
    
    # Test synthetic dataset creation
    logger.info("1. Testing synthetic dataset creation...")
    df = processor.load_cicids2017_dataset("nonexistent_file.csv")
    
    if df is not None:
        logger.info(f"‚úÖ Dataset created: {df.shape}")
        logger.info(f"‚úÖ Columns: {list(df.columns)}")
        logger.info(f"‚úÖ Label distribution:\n{df['Label'].value_counts()}")
    else:
        logger.error("‚ùå Failed to create dataset")
        return False
    
    # Test preprocessing
    logger.info("2. Testing data preprocessing...")
    try:
        X, y = processor.preprocess_data(df)
        logger.info(f"‚úÖ Preprocessing successful: X shape {X.shape}, y shape {y.shape}")
        logger.info(f"‚úÖ Feature columns: {len(processor.feature_columns)}")
    except Exception as e:
        logger.error(f"‚ùå Preprocessing failed: {e}")
        return False
    
    # Test DataLoader creation
    logger.info("3. Testing DataLoader creation...")
    try:
        train_loader, val_loader, test_loader = processor.create_dataloaders(X, y)
        logger.info(f"‚úÖ DataLoaders created successfully")
        logger.info(f"‚úÖ Train batches: {len(train_loader)}")
        logger.info(f"‚úÖ Val batches: {len(val_loader)}")
        logger.info(f"‚úÖ Test batches: {len(test_loader)}")
    except Exception as e:
        logger.error(f"‚ùå DataLoader creation failed: {e}")
        return False
    
    # Test feature importance analysis
    logger.info("4. Testing feature importance analysis...")
    try:
        feature_importance = processor.get_feature_importance_analysis(X, y)
        logger.info(f"‚úÖ Feature importance analysis completed")
    except Exception as e:
        logger.error(f"‚ùå Feature importance analysis failed: {e}")
        return False
    
    logger.info("‚úÖ All preprocessing tests passed!")
    return True

def test_feature_extraction():
    """Test network feature extraction"""
    logger.info("=== Testing Network Feature Extraction ===")
    
    try:
        from scapy.all import IP, TCP, UDP, Ether
        
        # Initialize extractor
        extractor = NetworkFeatureExtractor()
        logger.info(f"‚úÖ Feature extractor initialized with {len(extractor.feature_names)} features")
        
        # Create test packets
        logger.info("1. Testing packet feature extraction...")
        
        # TCP packet
        tcp_packet = Ether()/IP(src="192.168.1.10", dst="192.168.1.1")/TCP(sport=12345, dport=80, flags="S")
        tcp_features = extractor.extract_packet_features(tcp_packet)
        logger.info(f"‚úÖ TCP packet features extracted: {len(tcp_features)} features")
        
        # UDP packet
        udp_packet = Ether()/IP(src="192.168.1.10", dst="8.8.8.8")/UDP(sport=53, dport=53)
        udp_features = extractor.extract_packet_features(udp_packet)
        logger.info(f"‚úÖ UDP packet features extracted: {len(udp_features)} features")
        
        # Test flow creation
        logger.info("2. Testing flow feature calculation...")
        
        # Simulate a flow with multiple packets
        packets = [
            Ether()/IP(src="192.168.1.10", dst="192.168.1.1")/TCP(sport=12345, dport=80, flags="S"),
            Ether()/IP(src="192.168.1.1", dst="192.168.1.10")/TCP(sport=80, dport=12345, flags="SA"),
            Ether()/IP(src="192.168.1.10", dst="192.168.1.1")/TCP(sport=12345, dport=80, flags="A"),
            Ether()/IP(src="192.168.1.10", dst="192.168.1.1")/TCP(sport=12345, dport=80, flags="PA"),
        ]
        
        flow_features = None
        for packet in packets:
            flow_features = extractor.process_packet(packet)
        
        if flow_features:
            logger.info(f"‚úÖ Flow features calculated: {len(flow_features)} features")
            logger.info(f"‚úÖ Sample features: flow_duration={flow_features.get('flow_duration', 0):.2f}")
        else:
            logger.error("‚ùå Flow feature calculation failed")
            return False
        
        logger.info("‚úÖ All feature extraction tests passed!")
        return True
        
    except ImportError:
        logger.warning("‚ö†Ô∏è Scapy not available in this environment, skipping packet tests")
        return True
    except Exception as e:
        logger.error(f"‚ùå Feature extraction test failed: {e}")
        return False

if __name__ == "__main__":
    logger.info("Starting Faza 2 tests...")
    
    # Test data preprocessing
    if not test_data_preprocessing():
        logger.error("Data preprocessing tests failed!")
        sys.exit(1)
    
    # Test feature extraction
    if not test_feature_extraction():
        logger.error("Feature extraction tests failed!")
        sys.exit(1)
    
    logger.info("üéâ All Faza 2 tests passed successfully!")